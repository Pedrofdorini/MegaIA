{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef19662-411a-46b3-a91e-6151f14e8b51",
   "metadata": {},
   "source": [
    "# Fazendo a extração de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d13b7c-4891-47ae-b4b2-d22eb3ad4284",
   "metadata": {},
   "source": [
    "###Código Principal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f62854-0f86-4f25-bc46-ae69b4457333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_adds(concurso):\n",
    "    url = f\"https://www.megasena.com/resultados/{concurso}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = bs(response.content, 'html.parser')\n",
    "\n",
    "        #pegar a arrecadação total\n",
    "        winners_box = soup.find('div', class_='gen-box winners')\n",
    "        if winners_box:\n",
    "            arrecadacao= winners_box.find('div', class_='sub-title').get_text(strip=True)\n",
    "        else:\n",
    "            arrecadacao=None\n",
    "\n",
    "        #informação final\n",
    "        inners_box_2= soup.find('div', class_=\"inner-box elem-2\")\n",
    "        if inners_box_2:\n",
    "            gen_boxes= inners_box_2.find_all('div',class_=\"gen-box\")\n",
    "            row_data={}\n",
    "            \n",
    "            for gen_box in gen_boxes:\n",
    "                title=gen_box.find('div',class_=\"title\").get_text(strip=True)\n",
    "                sub_title= gen_box.find('div',class_=\"sub-title\").get_text(strip=True)\n",
    "\n",
    "                row_data[title]=sub_title\n",
    "                row_data[\"arrecadação\"]=arrecadacao\n",
    "                row_data[\"Número do Concurso\"]= concurso\n",
    "\n",
    "            return [row_data]\n",
    "        else:\n",
    "            return {\"Número do Concurso\": concurso, \"arrecadação\": arrecadacao}\n",
    "    else:\n",
    "        print(f\"Não foi possível estabelecer uma requisição HTTP, código de erro: {response.status_code}\")\n",
    "        return None\n",
    "        \n",
    "def fetch_table(concurso):\n",
    "    url = f\"https://www.megasena.com/resultados/{concurso}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = bs(response.content, 'html.parser')                  \n",
    "        # Pegar a data do concurso\n",
    "        h1_tag = soup.find(\"h1\")\n",
    "        if h1_tag:\n",
    "            span_tag = h1_tag.find(\"span\")\n",
    "            data_concurso = span_tag.text.strip()\n",
    "        else:\n",
    "            data_concurso = None\n",
    "        \n",
    "        # Extrair os números sorteados\n",
    "        balls = soup.find_all(\"li\", class_=\"ball\")\n",
    "        if len(balls) == 6:\n",
    "            numeros_sorteados = [ball.text.strip() for ball in balls]\n",
    "        else:\n",
    "            numeros_sorteados = None\n",
    "\n",
    "        table = soup.find(\"table\", class_=\"_numbers -right table-col-4 mobFormat\")\n",
    "        if table:\n",
    "            headers = [th.text.strip() for th in table.find_all('th')]\n",
    "            rows = table.find_all('tr')[1:]  # Skip header row\n",
    "\n",
    "            data = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if cells:\n",
    "                    row_data = {headers[i]: cells[i].text.strip() for i in range(len(cells))}\n",
    "                    row_data[\"Data do Concurso\"] = data_concurso\n",
    "                    row_data[\"Número do Concurso\"]= concurso\n",
    "                    row_data[\"Números Sorteados\"] = \", \".join(numeros_sorteados) if numeros_sorteados else None\n",
    "                    data.append(row_data)\n",
    "\n",
    "            return data\n",
    "        else:\n",
    "            print(\"Tabela não encontrada na página.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Não foi possível estabelecer uma requisição HTTP, código de erro: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def fetch_ganhadores_por_estado(concurso):\n",
    "    url = f\"https://www.megasena.com/resultados/{concurso}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = bs(response.content, 'html.parser')\n",
    "\n",
    "        table = soup.find(\"table\", class_=\"_numbers -right mobFormat\")\n",
    "        if table:\n",
    "            headers = [th.text.strip() for th in table.find_all('th')]\n",
    "            rows = table.find_all('tr')[1:]  # Skip header row\n",
    "\n",
    "            data = []\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if cells:\n",
    "                    row_data = {headers[i]: cells[i].text.strip() for i in range(len(cells))}\n",
    "                    data.append(row_data)\n",
    "\n",
    "            return data\n",
    "        else:\n",
    "            print(\"Tabela de ganhadores por estado não encontrada na página.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Não foi possível estabelecer uma requisição HTTP, código de erro: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def save_to_excel(data_principal, data_ganhadores,data_adicional, filename):\n",
    "    df_principal = pd.DataFrame(data_principal)\n",
    "    df_ganhadores = pd.DataFrame(data_ganhadores)\n",
    "    df_adicional= pd.DataFrame(data_adicional)\n",
    "    \n",
    "    with pd.ExcelWriter(filename) as writer:\n",
    "        df_principal.to_excel(writer, sheet_name=\"dados gerais\", index=False)\n",
    "        df_ganhadores.to_excel(writer, sheet_name=\"Ganhadores por Estado\", index=False)\n",
    "        df_adicional.to_excel(writer,sheet_name= \"Dados isolados\", index=False)\n",
    "        \n",
    "    \n",
    "    print(f\"Dados salvos no arquivo {filename}\")\n",
    "\n",
    "def main():\n",
    "    all_data_principal = []\n",
    "    all_data_ganhadores = []\n",
    "    all_data_adicional = []\n",
    "    concursos=list(range(2760,0,-1))\n",
    "    for concurso in tqdm(concursos, desc=\"Collecting Data\"):  # Intervalo de concursos em ordem decrescente\n",
    "        data_principal = fetch_table(concurso)\n",
    "        if data_principal:\n",
    "            all_data_principal.extend(data_principal)  # Acumular dados de todos os concursos\n",
    "        \n",
    "        data_ganhadores = fetch_ganhadores_por_estado(concurso)\n",
    "        if data_ganhadores:\n",
    "            for item in data_ganhadores:\n",
    "                item[\"Concurso\"] = concurso\n",
    "            all_data_ganhadores.extend(data_ganhadores)  # Acumular dados de ganhadores por estado\n",
    "        data_adicional = fetch_adds(concurso)\n",
    "        if data_adicional:\n",
    "            all_data_adicional.extend(data_adicional)\n",
    "\n",
    "        \n",
    "\n",
    "    if all_data_principal and all_data_ganhadores and all_data_adicional:\n",
    "        save_to_excel(all_data_principal, all_data_ganhadores,all_data_adicional ,\"megasena_resultados.xlsx\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcec788a-f5cc-41e3-8942-75aeb8fe390b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.4/78.4 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\onedrive\\área de trabalho\\data\\megacena\\megaia\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.9/64.9 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "     ---------------------------------------- 99.9/99.9 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "     ---------------------------------------- 66.8/66.8 kB 1.8 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "     -------------------------------------- 121.4/121.4 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "     ------------------------------------ 163.0/163.0 kB 979.0 kB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2024.7.4 charset-normalizer-3.3.2 idna-3.7 requests-2.32.3 urllib3-2.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "     -------------------------------------- 147.9/147.9 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "     --------------------------------------- 11.6/11.6 MB 50.4 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.23.2\n",
      "  Downloading numpy-2.0.1-cp311-cp311-win_amd64.whl (16.6 MB)\n",
      "     ---------------------------------------- 16.6/16.6 MB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\onedrive\\área de trabalho\\data\\megacena\\megaia\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\onedrive\\área de trabalho\\data\\megacena\\megaia\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.0.1 pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (megaia)",
   "language": "python",
   "name": "megaia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
